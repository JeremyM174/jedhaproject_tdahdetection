{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMTE-gy8QrZx"
      },
      "source": [
        "**Étapes pour utiliser le code :**\n",
        "\n",
        "1. Préparez votre dataset comme décrit, avec les images dans un dossier et le fichier CSV des labels.\n",
        "\n",
        "2. Mettez à jour les variables DATA_DIR, CSV_FILE, IMAGE_DIR, et surtout la liste EMOTION_LABELS pour qu'elle corresponde exactement à vos émotions et l'ordre de vos colonnes dans le CSV.\n",
        "\n",
        "3. Exécutez le script.\n",
        "\n",
        "4. Surveillez la console pour les métriques d'entraînement et de validation. Ajustez les hyperparamètres (BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, FREEZE_FEATURES) si nécessaire en fonction des performances observées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLKa9aKKRG7N"
      },
      "source": [
        "**Organisation des données :**\n",
        "\n",
        "your_dataset/\n",
        "\n",
        "├── images/\n",
        "\n",
        "│   ├── image_001.jpg\n",
        "\n",
        "│   ├── image_002.jpg\n",
        "\n",
        "│   └── ...\n",
        "\n",
        "└── labels.csv # Ou un autre format de fichier, contenant les chemins d'images et leurs étiquettes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD1t0ktwWJ0U"
      },
      "source": [
        "**Format du dataset :**\n",
        "\n",
        "![Capture d'écran 2025-07-21 161638.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "17t4rr1xS1ja"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import models#, transforms\n",
        "import torchvision.transforms.v2 as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, mean_squared_error\n",
        "import numpy as np\n",
        "from tqdm import tqdm # Pour les barres de progression\n",
        "\n",
        "#import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vOu_5EUt30"
      },
      "source": [
        "On a le choix de fine tuner la dernière couche OU tout le modele (pas le même temps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# I/ Configuration et Hyperparamètres "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b1KN8LGLS6gP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utilisation du périphérique : cuda:0\n"
          ]
        }
      ],
      "source": [
        "# --- 0. Configuration et Hyperparamètres ---\n",
        "DATA_DIR = r'C:\\Users\\alber\\Desktop\\visual_studio_code\\dossier_jedha\\Jedha_Full_stack\\00_Final_Project\\emotic' # Chemin vers votre dossier racine du dataset\n",
        "CSV_FILE = os.path.join(DATA_DIR, 'labels.csv') # Chemin vers votre fichier CSV d'étiquettes\n",
        "IMAGE_DIR = os.path.join(DATA_DIR, 'images') # Chemin vers le dossier contenant les images\n",
        "\n",
        "BODY_BBOX_COLS = ['body_bbox_x1', 'body_bbox_y1', 'body_bbox_x2', 'body_bbox_y2'] # Noms de vos colonnes de face_box dans le CSV\n",
        "\n",
        "# Définissez vos émotions binaires ici, dans le même ordre que vos colonnes dans le CSV\n",
        "EMOTION_LABELS = [\n",
        "    'Disconnection',\n",
        "    'Doubt/Confusion',\n",
        "    'Fatigue',\n",
        "    'Pain',\n",
        "    'Disquietment',\n",
        "    'Annoyance',\n",
        "    'others',\n",
        "    'adhd_emotion'\n",
        "]\n",
        "\n",
        "NUM_CLASSES = len(EMOTION_LABELS)\n",
        "\n",
        "BATCH_SIZE = 32 \n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "FREEZE_FEATURES = True # True pour ne fine-tuner que la dernière couche, False pour fine-tuner tout le modèle\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation du périphérique : {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alber\\Desktop\\visual_studio_code\\dossier_jedha\\Jedha_Full_stack\\00_Final_Project\\emotic\n",
            "C:\\Users\\alber\\Desktop\\visual_studio_code\\dossier_jedha\\Jedha_Full_stack\\00_Final_Project\\emotic\\labels.csv\n",
            "C:\\Users\\alber\\Desktop\\visual_studio_code\\dossier_jedha\\Jedha_Full_stack\\00_Final_Project\\emotic\\images\n"
          ]
        }
      ],
      "source": [
        "print(DATA_DIR)\n",
        "print(CSV_FILE)\n",
        "print(IMAGE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Toutes les images référencées dans le CSV sont présentes dans le dossier images/\n"
          ]
        }
      ],
      "source": [
        "# Charger le fichier CSV des annotations\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "# Vérifie qu'une colonne 'image' ou 'filename' existe\n",
        "assert 'image' in df.columns or 'filename' in df.columns, \"❌ Le fichier CSV ne contient pas de colonne 'image' ou 'filename'.\"\n",
        "\n",
        "# Nom de la colonne contenant les noms d'image\n",
        "image_column = 'image' if 'image' in df.columns else 'filename'\n",
        "\n",
        "# Vérification de l'existence des fichiers image\n",
        "missing_images = []\n",
        "for img_name in df[image_column].unique():\n",
        "    img_path = os.path.join(IMAGE_DIR, img_name)\n",
        "    if not os.path.isfile(img_path):\n",
        "        missing_images.append(img_name)\n",
        "\n",
        "# Affichage du résultat\n",
        "if missing_images:\n",
        "    print(f\"❌ {len(missing_images)} image(s) manquante(s) sur {df[image_column].nunique()} :\")\n",
        "    print(missing_images[:10])  # Affiche les 10 premières si la liste est longue\n",
        "else:\n",
        "    print(\"✅ Toutes les images référencées dans le CSV sont présentes dans le dossier images/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# II/ Création du Dataset PyTorch personnalisé (modifié)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i1HiG6PTReS"
      },
      "outputs": [],
      "source": [
        "# --- 1. Création du Dataset PyTorch personnalisé (modifié) ---\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, emotion_cols, bbox_cols, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.emotion_cols = emotion_cols\n",
        "        self.bbox_cols = bbox_cols # Nouvelle ligne pour les colonnes de la bbox\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['image'])\n",
        "\n",
        "        emotion_labels = row[self.emotion_cols].values.astype(float)\n",
        "        emotion_labels = torch.tensor(emotion_labels, dtype=torch.float32)\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        x1, y1, x2, y2 = row[self.bbox_cols].values.astype(int)\n",
        "        cropped_image = image.crop((x1, y1, x2, y2))\n",
        "        \n",
        "        if self.transform:\n",
        "            cropped_image = self.transform(cropped_image)\n",
        "\n",
        "        return cropped_image, emotion_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de lecture de l'image : C:\\Users\\alber\\Desktop\\visual_studio_code\\dossier_jedha\\Jedha_Full_stack\\00_Final_Project\\emotic\\images\\COCO_train2014_000000370524.jpg\n",
            "✅ Image lue correctement. Taille = (640, 495)\n",
            "⏱ Temps de lecture : 0.0110 secondes\n"
          ]
        }
      ],
      "source": [
        "# Chargement du CSV\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "# Prendre une ligne aléatoire\n",
        "sample_row = df.sample(1).iloc[0]\n",
        "img_name = sample_row['image']  # colonne contenant le nom du fichier image\n",
        "img_path = os.path.join(IMAGE_DIR, img_name)\n",
        "\n",
        "print(f\"Test de lecture de l'image : {img_path}\")\n",
        "\n",
        "# Mesure du temps de lecture\n",
        "start = time.time()\n",
        "try:\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img.load()  # Force le chargement complet\n",
        "    print(f\"✅ Image lue correctement. Taille = {img.size}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur de lecture de l'image : {e}\")\n",
        "\n",
        "end = time.time()\n",
        "print(f\"⏱ Temps de lecture : {end - start:.4f} secondes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# III/ Transformations d'images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LkV1CWUbTUJB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\alber\\anaconda3\\envs\\dl_project_py311\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Transformations d'images ---\n",
        "# Transformations pour l'entraînement (augmentation des données)\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224), # Recadrage aléatoire et redimensionnement à 224x224\n",
        "        transforms.RandomHorizontalFlip(), # Retournement horizontal aléatoire\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Jitter de couleur\n",
        "        transforms.ToTensor(), # Convertir en Tensor PyTorch (met les pixels entre 0 et 1)\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalisation (moyenne et std ImageNet)\n",
        "    ]),\n",
        "    # Transformations pour la validation/test (juste redimensionnement et normalisation)\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256), # Redimensionner le plus petit côté à 256\n",
        "        transforms.CenterCrop(224), # Centre Crop à 224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IV/ Chargement des données et division Train/Val "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mNFgbICTrGD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement des données...\n",
            "Taille du dataset d'entraînement : 13516\n",
            "Taille du dataset de validation : 3380\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Chargement des données et division Train/Val ---\n",
        "print(\"Chargement des données...\")\n",
        "full_df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "# Division du dataset en ensembles d'entraînement et de validation\n",
        "train_df, val_df = train_test_split(full_df, test_size=0.2, random_state=42, stratify=full_df['adhd_emotion'] if True else None) # Stratify si possible\n",
        "\n",
        "train_dataset = EmotionDataset(df=train_df, img_dir=IMAGE_DIR, emotion_cols=EMOTION_LABELS, bbox_cols=BODY_BBOX_COLS, transform=data_transforms['train'])\n",
        "val_dataset = EmotionDataset(df=val_df, img_dir=IMAGE_DIR, emotion_cols=EMOTION_LABELS, bbox_cols=BODY_BBOX_COLS, transform=data_transforms['val'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        "\n",
        "print(f\"Taille du dataset d'entraînement : {dataset_sizes['train']}\")\n",
        "print(f\"Taille du dataset de validation : {dataset_sizes['val']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[-1.3815, -1.3815, -1.3644,  ..., -1.4329, -1.4329, -1.4329],\n",
              "          [-1.3815, -1.3815, -1.3644,  ..., -1.4329, -1.4329, -1.4329],\n",
              "          [-1.3815, -1.3815, -1.3815,  ..., -1.4329, -1.4329, -1.4329],\n",
              "          ...,\n",
              "          [ 0.7419,  0.7419,  0.7419,  ..., -0.3198, -0.2856, -0.2856],\n",
              "          [ 0.7248,  0.7248,  0.7248,  ..., -0.3369, -0.3027, -0.3027],\n",
              "          [ 0.7248,  0.7248,  0.7248,  ..., -0.3369, -0.3027, -0.3027]],\n",
              " \n",
              "         [[-1.2829, -1.2829, -1.2829,  ..., -1.3704, -1.3704, -1.3704],\n",
              "          [-1.2829, -1.2829, -1.2829,  ..., -1.3704, -1.3704, -1.3704],\n",
              "          [-1.3004, -1.3004, -1.2829,  ..., -1.3704, -1.3704, -1.3704],\n",
              "          ...,\n",
              "          [ 0.8354,  0.8354,  0.8354,  ..., -0.1800, -0.1275, -0.1275],\n",
              "          [ 0.8179,  0.8179,  0.8179,  ..., -0.1975, -0.1450, -0.1450],\n",
              "          [ 0.8179,  0.8179,  0.8179,  ..., -0.1975, -0.1450, -0.1450]],\n",
              " \n",
              "         [[-0.9853, -0.9853, -0.9678,  ..., -1.0898, -1.0898, -1.0898],\n",
              "          [-0.9853, -0.9853, -0.9678,  ..., -1.0898, -1.0898, -1.0898],\n",
              "          [-1.0027, -1.0027, -0.9853,  ..., -1.0898, -1.0898, -1.0898],\n",
              "          ...,\n",
              "          [ 1.0539,  1.0539,  1.0539,  ...,  0.0082,  0.0256,  0.0256],\n",
              "          [ 1.0365,  1.0365,  1.0365,  ..., -0.0267,  0.0256,  0.0256],\n",
              "          [ 1.0365,  1.0365,  1.0365,  ..., -0.0267,  0.0256,  0.0256]]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 0.]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]  # ou un autre index si ça bloque toujours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[[ 0.6734,  0.5364,  0.3481,  ...,  2.1804,  2.1462,  2.1119],\n",
              "           [ 0.7248,  0.6221,  0.4679,  ...,  2.1633,  2.1633,  2.1462],\n",
              "           [ 0.7933,  0.6906,  0.5878,  ...,  2.1119,  2.1462,  2.1633],\n",
              "           ...,\n",
              "           [ 0.5878,  0.5707,  0.5878,  ..., -1.2959, -1.3473, -1.3815],\n",
              "           [ 0.6049,  0.5878,  0.6049,  ..., -1.1760, -1.2445, -1.3130],\n",
              "           [ 0.6049,  0.5878,  0.6049,  ..., -1.0904, -1.1589, -1.2103]],\n",
              " \n",
              "          [[ 0.8004,  0.6779,  0.5203,  ...,  1.2381,  1.2206,  1.1856],\n",
              "           [ 0.9055,  0.7829,  0.6429,  ...,  1.2381,  1.2206,  1.2031],\n",
              "           [ 0.9755,  0.8704,  0.7654,  ...,  1.2031,  1.2031,  1.2206],\n",
              "           ...,\n",
              "           [ 0.3102,  0.2402,  0.2052,  ..., -1.7556, -1.7906, -1.7906],\n",
              "           [ 0.3277,  0.2577,  0.2227,  ..., -1.6856, -1.7381, -1.7906],\n",
              "           [ 0.3277,  0.2752,  0.2402,  ..., -1.6331, -1.6681, -1.7206]],\n",
              " \n",
              "          [[ 1.1585,  1.0539,  0.9145,  ...,  1.2980,  1.2631,  1.2457],\n",
              "           [ 1.2805,  1.1934,  1.0714,  ...,  1.2980,  1.2631,  1.2631],\n",
              "           [ 1.3502,  1.2805,  1.1934,  ...,  1.2457,  1.2457,  1.2631],\n",
              "           ...,\n",
              "           [ 0.6182,  0.5834,  0.5659,  ..., -1.5779, -1.6127, -1.6127],\n",
              "           [ 0.6356,  0.6008,  0.5834,  ..., -1.5081, -1.5604, -1.5953],\n",
              "           [ 0.6531,  0.6008,  0.5834,  ..., -1.4733, -1.4907, -1.5256]]],\n",
              " \n",
              " \n",
              "         [[[-1.8097, -1.8268, -1.8268,  ..., -1.6555, -1.6727, -1.6555],\n",
              "           [-1.8097, -1.7925, -1.8268,  ..., -1.6727, -1.6898, -1.7069],\n",
              "           [-1.8097, -1.8268, -1.8097,  ..., -1.6898, -1.6898, -1.6555],\n",
              "           ...,\n",
              "           [-0.7137, -0.5596, -0.1828,  ..., -0.4397, -0.4054, -0.4054],\n",
              "           [-0.6281, -0.5424, -0.2171,  ..., -0.4054, -0.4054, -0.3369],\n",
              "           [-0.6794, -0.6281, -0.3712,  ..., -0.3883, -0.3541, -0.3712]],\n",
              " \n",
              "          [[-1.7031, -1.7031, -1.7031,  ..., -1.4580, -1.4580, -1.4580],\n",
              "           [-1.6506, -1.6681, -1.7031,  ..., -1.4055, -1.4230, -1.4580],\n",
              "           [-1.6681, -1.6331, -1.6331,  ..., -1.4580, -1.4405, -1.4405],\n",
              "           ...,\n",
              "           [-1.1429, -0.9853, -0.7577,  ..., -0.1450, -0.1099, -0.1450],\n",
              "           [-1.2654, -1.1253, -0.8803,  ..., -0.1275, -0.1275, -0.0749],\n",
              "           [-1.2829, -1.2304, -1.0203,  ..., -0.1275, -0.0749, -0.0924]],\n",
              " \n",
              "          [[-1.3861, -1.4384, -1.4210,  ..., -1.1770, -1.1944, -1.1944],\n",
              "           [-1.3687, -1.4036, -1.4210,  ..., -1.1770, -1.1944, -1.2293],\n",
              "           [-1.3687, -1.3861, -1.3513,  ..., -1.2293, -1.2293, -1.2119],\n",
              "           ...,\n",
              "           [-1.4036, -1.4384, -1.3861,  ..., -0.1312, -0.0790, -0.0964],\n",
              "           [-1.5430, -1.5081, -1.4559,  ..., -0.0964, -0.1138, -0.0441],\n",
              "           [-1.6127, -1.5604, -1.5256,  ..., -0.1312, -0.1138, -0.1138]]],\n",
              " \n",
              " \n",
              "         [[[ 1.5810,  1.7352,  1.6838,  ...,  1.6324,  1.6667,  1.7694],\n",
              "           [ 1.4954,  1.5297,  1.5982,  ...,  1.6838,  1.5982,  1.6324],\n",
              "           [ 1.1358,  1.2557,  1.3927,  ...,  1.6495,  1.6324,  1.6153],\n",
              "           ...,\n",
              "           [ 0.7077,  0.7419,  0.8104,  ..., -0.3198, -0.3883, -0.7308],\n",
              "           [ 0.6906,  0.7248,  0.7762,  ..., -0.3712, -0.5767, -0.9705],\n",
              "           [ 0.6734,  0.7248,  0.7591,  ..., -0.4226, -0.7308, -1.1589]],\n",
              " \n",
              "          [[ 1.6408,  1.7983,  1.7458,  ...,  0.2402,  0.1352,  0.0126],\n",
              "           [ 1.6057,  1.6583,  1.7458,  ...,  0.3978,  0.3627,  0.3978],\n",
              "           [ 1.1506,  1.2731,  1.4482,  ...,  0.5728,  0.6078,  0.5728],\n",
              "           ...,\n",
              "           [ 0.8354,  0.8704,  0.9405,  ..., -1.1779, -1.2304, -1.4755],\n",
              "           [ 0.8179,  0.8529,  0.9055,  ..., -1.2479, -1.4230, -1.6681],\n",
              "           [ 0.8004,  0.8529,  0.8880,  ..., -1.3004, -1.5455, -1.7731]],\n",
              " \n",
              "          [[ 1.6640,  1.8557,  1.8208,  ..., -0.0441, -0.1487, -0.2184],\n",
              "           [ 1.6117,  1.6640,  1.7685,  ...,  0.1302,  0.0605,  0.0953],\n",
              "           [ 1.1585,  1.3154,  1.4722,  ...,  0.2522,  0.2348,  0.1999],\n",
              "           ...,\n",
              "           [ 0.9668,  1.0017,  1.0714,  ..., -1.3687, -1.4210, -1.5953],\n",
              "           [ 0.9494,  0.9842,  1.0365,  ..., -1.4210, -1.5081, -1.6999],\n",
              "           [ 0.9319,  0.9842,  1.0191,  ..., -1.4384, -1.5604, -1.7347]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[ 0.5878,  0.6049,  0.5878,  ..., -1.6042, -1.6042, -1.6042],\n",
              "           [ 0.5878,  0.6221,  0.6906,  ..., -1.6042, -1.6042, -1.6042],\n",
              "           [ 0.5364,  0.5193,  0.6563,  ..., -1.6042, -1.6042, -1.6042],\n",
              "           ...,\n",
              "           [ 0.3994,  0.5878,  0.5878,  ...,  0.9303,  0.9132,  0.8961],\n",
              "           [ 0.5364,  0.6392,  0.7077,  ...,  0.9474,  0.9132,  0.8789],\n",
              "           [ 0.6906,  0.7077,  0.8104,  ...,  0.9474,  0.9132,  0.8961]],\n",
              " \n",
              "          [[ 0.2227,  0.2402,  0.2402,  ..., -1.5105, -1.5105, -1.5105],\n",
              "           [ 0.2052,  0.2577,  0.3452,  ..., -1.5105, -1.5105, -1.5105],\n",
              "           [ 0.1352,  0.1527,  0.3102,  ..., -1.5105, -1.5105, -1.5105],\n",
              "           ...,\n",
              "           [-0.2325, -0.0749, -0.1099,  ...,  0.2752,  0.2402,  0.2227],\n",
              "           [-0.1975, -0.1099, -0.0399,  ...,  0.2752,  0.2402,  0.2227],\n",
              "           [-0.1099, -0.0924,  0.0301,  ...,  0.2752,  0.2577,  0.2402]],\n",
              " \n",
              "          [[-0.2532, -0.2184, -0.2184,  ..., -1.2816, -1.2816, -1.2816],\n",
              "           [-0.2532, -0.2184, -0.1312,  ..., -1.2816, -1.2816, -1.2816],\n",
              "           [-0.3230, -0.3230, -0.1661,  ..., -1.2816, -1.2816, -1.2816],\n",
              "           ...,\n",
              "           [-0.3404, -0.1661, -0.1835,  ...,  0.2173,  0.1825,  0.1651],\n",
              "           [-0.2881, -0.2010, -0.1312,  ...,  0.2173,  0.1825,  0.1651],\n",
              "           [-0.1835, -0.1835, -0.0790,  ...,  0.2173,  0.1999,  0.1825]]],\n",
              " \n",
              " \n",
              "         [[[ 2.1804,  2.2318,  2.2489,  ...,  1.6153,  1.5982,  1.6153],\n",
              "           [ 2.1119,  2.2318,  2.2489,  ...,  1.5468,  1.5639,  1.6153],\n",
              "           [ 2.1119,  2.1633,  2.1633,  ...,  1.4612,  1.5125,  1.5639],\n",
              "           ...,\n",
              "           [ 1.8037,  1.8379,  1.8208,  ...,  0.9303,  1.0673,  1.1187],\n",
              "           [ 1.7865,  1.8208,  1.8379,  ...,  0.4851,  0.5364,  0.6734],\n",
              "           [ 1.7865,  1.8379,  1.8550,  ...,  0.5022,  0.5022,  0.5536]],\n",
              " \n",
              "          [[ 2.1134,  2.0609,  1.9734,  ...,  0.5553,  0.6604,  0.7129],\n",
              "           [ 2.0434,  2.0084,  1.9209,  ...,  0.5378,  0.6779,  0.7829],\n",
              "           [ 2.0259,  1.9384,  1.8333,  ...,  0.5028,  0.6429,  0.7654],\n",
              "           ...,\n",
              "           [ 1.6758,  1.7108,  1.6933,  ...,  0.7129,  0.8704,  0.9230],\n",
              "           [ 1.6583,  1.6933,  1.7108,  ...,  0.2227,  0.2752,  0.4153],\n",
              "           [ 1.6583,  1.7108,  1.7283,  ...,  0.1877,  0.1877,  0.2577]],\n",
              " \n",
              "          [[ 2.0997,  2.0997,  2.0648,  ...,  0.9145,  1.0539,  1.1934],\n",
              "           [ 2.0300,  2.0823,  2.0474,  ...,  0.8274,  1.0017,  1.1585],\n",
              "           [ 2.0125,  2.0125,  1.9603,  ...,  0.7402,  0.9145,  1.0539],\n",
              "           ...,\n",
              "           [ 1.6117,  1.6465,  1.6291,  ...,  0.7228,  0.8448,  0.8797],\n",
              "           [ 1.5942,  1.6291,  1.6465,  ...,  0.3045,  0.3219,  0.4439],\n",
              "           [ 1.5942,  1.6465,  1.6640,  ...,  0.3393,  0.3219,  0.3568]]],\n",
              " \n",
              " \n",
              "         [[[-1.0562, -1.1932, -1.2788,  ..., -1.0733, -1.3473, -1.6042],\n",
              "           [-1.0904, -1.2103, -1.2617,  ..., -1.1075, -1.3644, -1.6042],\n",
              "           [-1.1247, -1.2103, -1.1932,  ..., -1.1760, -1.3815, -1.5699],\n",
              "           ...,\n",
              "           [-1.8782, -1.8610, -1.8439,  ...,  0.0056, -0.0116, -0.0801],\n",
              "           [-1.8953, -1.8953, -1.8953,  ...,  0.0056,  0.0741,  0.1083],\n",
              "           [-1.9295, -1.9295, -1.9295,  ..., -0.3883, -0.3198, -0.2342]],\n",
              " \n",
              "          [[-0.8102, -0.9328, -1.0028,  ..., -0.7927, -0.9503, -1.1078],\n",
              "           [-0.8627, -0.9678, -0.9853,  ..., -0.8452, -0.9853, -1.1253],\n",
              "           [-0.8978, -0.9503, -0.9153,  ..., -0.9153, -1.0203, -1.1253],\n",
              "           ...,\n",
              "           [-1.7206, -1.7031, -1.6856,  ..., -0.7227, -0.7577, -0.8102],\n",
              "           [-1.7381, -1.7381, -1.7381,  ..., -0.8627, -0.8277, -0.7927],\n",
              "           [-1.7731, -1.7731, -1.7731,  ..., -1.3704, -1.3529, -1.2829]],\n",
              " \n",
              "          [[-0.3578, -0.4973, -0.5844,  ...,  0.2173,  0.0431, -0.1138],\n",
              "           [-0.3927, -0.5321, -0.5844,  ...,  0.1651,  0.0082, -0.1487],\n",
              "           [-0.4275, -0.5147, -0.5147,  ...,  0.0953, -0.0267, -0.1661],\n",
              "           ...,\n",
              "           [-1.5081, -1.4559, -1.4036,  ..., -0.4973, -0.6018, -0.7587],\n",
              "           [-1.5256, -1.4907, -1.4559,  ..., -0.6541, -0.7238, -0.8284],\n",
              "           [-1.5604, -1.5256, -1.4907,  ..., -1.1770, -1.2990, -1.3513]]]]),\n",
              " tensor([[0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.]])]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(val_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[[-1.4329, -1.4329, -1.4329,  ..., -1.0562, -1.0390, -1.0390],\n",
              "           [-1.4329, -1.4329, -1.4329,  ..., -1.0562, -1.0390, -1.0390],\n",
              "           [-1.4500, -1.4500, -1.4329,  ..., -1.0733, -1.0390, -1.0390],\n",
              "           ...,\n",
              "           [-1.5870, -1.5870, -1.5870,  ...,  0.3994,  0.3994,  0.3994],\n",
              "           [-1.5870, -1.5870, -1.5870,  ...,  0.3994,  0.3994,  0.3994],\n",
              "           [-1.5870, -1.5870, -1.5870,  ...,  0.3994,  0.3994,  0.3994]],\n",
              " \n",
              "          [[-1.5980, -1.5980, -1.5980,  ..., -1.3179, -1.3004, -1.3004],\n",
              "           [-1.5980, -1.5980, -1.5980,  ..., -1.3179, -1.3004, -1.3004],\n",
              "           [-1.6155, -1.6155, -1.6155,  ..., -1.3354, -1.3004, -1.3004],\n",
              "           ...,\n",
              "           [-1.8081, -1.8081, -1.8081,  ..., -0.1975, -0.1975, -0.1975],\n",
              "           [-1.8081, -1.8081, -1.8081,  ..., -0.1975, -0.1975, -0.1975],\n",
              "           [-1.8081, -1.8081, -1.8081,  ..., -0.1975, -0.1975, -0.1975]],\n",
              " \n",
              "          [[-1.5779, -1.5779, -1.5779,  ..., -1.2990, -1.2641, -1.2641],\n",
              "           [-1.5779, -1.5779, -1.5779,  ..., -1.2990, -1.2641, -1.2641],\n",
              "           [-1.5779, -1.5779, -1.5779,  ..., -1.3164, -1.2641, -1.2641],\n",
              "           ...,\n",
              "           [-1.3687, -1.3687, -1.3861,  ..., -1.2641, -1.2641, -1.2641],\n",
              "           [-1.3687, -1.3687, -1.3861,  ..., -1.2641, -1.2641, -1.2641],\n",
              "           [-1.3687, -1.3687, -1.3861,  ..., -1.2641, -1.2641, -1.2641]]],\n",
              " \n",
              " \n",
              "         [[[-2.1179, -2.1179, -2.1179,  ..., -1.2103, -1.2788, -1.2617],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -1.2274, -1.2617, -1.2617],\n",
              "           [-2.1179, -2.1179, -2.1179,  ..., -1.2274, -1.2274, -1.2274],\n",
              "           ...,\n",
              "           [ 2.2147,  2.2147,  2.0605,  ...,  2.2147,  2.2147,  2.2147],\n",
              "           [ 2.2147,  2.2147,  2.0263,  ...,  2.2147,  2.2147,  2.2147],\n",
              "           [ 2.2147,  2.2147,  2.0434,  ...,  2.2147,  2.2147,  2.2147]],\n",
              " \n",
              "          [[-2.0357, -2.0357, -2.0357,  ..., -1.2304, -1.2829, -1.2654],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -1.2479, -1.2654, -1.2654],\n",
              "           [-2.0357, -2.0357, -2.0357,  ..., -1.2479, -1.2479, -1.2479],\n",
              "           ...,\n",
              "           [ 2.3936,  2.3936,  2.2360,  ...,  2.3936,  2.3936,  2.3936],\n",
              "           [ 2.3936,  2.3936,  2.2010,  ...,  2.3936,  2.3936,  2.3936],\n",
              "           [ 2.3936,  2.3936,  2.2185,  ...,  2.3936,  2.3936,  2.3936]],\n",
              " \n",
              "          [[-1.8044, -1.8044, -1.8044,  ..., -0.8807, -0.9330, -0.9156],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -0.8981, -0.9156, -0.9156],\n",
              "           [-1.8044, -1.8044, -1.8044,  ..., -0.8981, -0.8981, -0.8981],\n",
              "           ...,\n",
              "           [ 2.6051,  2.6051,  2.4483,  ...,  2.6051,  2.6051,  2.6051],\n",
              "           [ 2.6051,  2.6051,  2.4134,  ...,  2.6051,  2.6051,  2.6051],\n",
              "           [ 2.6051,  2.6051,  2.4308,  ...,  2.6051,  2.6051,  2.6051]]],\n",
              " \n",
              " \n",
              "         [[[ 1.7694,  1.7523,  1.7523,  ..., -0.4054, -0.4054, -0.4054],\n",
              "           [ 1.7865,  1.7352,  1.7009,  ..., -0.4054, -0.3883, -0.3541],\n",
              "           [ 1.8379,  1.7694,  1.7180,  ..., -0.4568, -0.4054, -0.3712],\n",
              "           ...,\n",
              "           [ 1.2385,  1.9235,  1.9920,  ..., -1.6898, -1.6555, -1.5870],\n",
              "           [ 1.9064,  1.8893,  1.7523,  ..., -1.7240, -1.7240, -1.6727],\n",
              "           [ 2.1633,  1.9920,  1.7865,  ..., -1.6898, -1.6555, -1.6555]],\n",
              " \n",
              "          [[ 2.0084,  1.9909,  1.9909,  ..., -0.3725, -0.3725, -0.3550],\n",
              "           [ 2.1134,  2.0259,  1.9909,  ..., -0.3725, -0.3725, -0.3725],\n",
              "           [ 2.1835,  2.0959,  2.0259,  ..., -0.4251, -0.4076, -0.3901],\n",
              "           ...,\n",
              "           [ 1.2731,  1.9209,  1.9734,  ..., -1.6681, -1.6506, -1.5980],\n",
              "           [ 1.9559,  1.9034,  1.7283,  ..., -1.6856, -1.7031, -1.6331],\n",
              "           [ 2.2535,  1.9909,  1.7458,  ..., -1.6506, -1.5980, -1.5980]],\n",
              " \n",
              "          [[ 2.3437,  2.3263,  2.3263,  ..., -0.2707, -0.2707, -0.2358],\n",
              "           [ 2.4308,  2.3437,  2.3088,  ..., -0.2707, -0.2707, -0.2184],\n",
              "           [ 2.4831,  2.4134,  2.3437,  ..., -0.3230, -0.2881, -0.2358],\n",
              "           ...,\n",
              "           [ 1.1237,  1.6988,  1.6291,  ..., -1.4733, -1.4559, -1.3861],\n",
              "           [ 1.8034,  1.6640,  1.4025,  ..., -1.5430, -1.5430, -1.4733],\n",
              "           [ 2.3437,  1.7685,  1.4374,  ..., -1.5081, -1.4559, -1.4559]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[ 0.7077,  0.6906,  0.6734,  ...,  0.9817,  0.9646,  0.9132],\n",
              "           [ 0.7248,  0.7077,  0.6906,  ...,  0.9817,  0.9474,  0.9132],\n",
              "           [ 0.7591,  0.7419,  0.7248,  ...,  0.9474,  0.9132,  0.8961],\n",
              "           ...,\n",
              "           [-1.0904, -1.0562, -1.0048,  ...,  0.6392,  0.6906,  0.7591],\n",
              "           [-1.1075, -1.0904, -1.0733,  ...,  0.6392,  0.6734,  0.7419],\n",
              "           [-1.1247, -1.1075, -1.0904,  ...,  0.6392,  0.6734,  0.7419]],\n",
              " \n",
              "          [[-0.3901, -0.3901, -0.4076,  ...,  0.0126, -0.0574, -0.0924],\n",
              "           [-0.3725, -0.3550, -0.3901,  ...,  0.0301, -0.0224, -0.0574],\n",
              "           [-0.3200, -0.3200, -0.3200,  ...,  0.0826,  0.0301,  0.0126],\n",
              "           ...,\n",
              "           [-1.1429, -1.0553, -0.9853,  ..., -0.1450, -0.0749, -0.0049],\n",
              "           [-1.1253, -1.0553, -1.0028,  ..., -0.1625, -0.1450, -0.1099],\n",
              "           [-1.1078, -1.0553, -1.0203,  ..., -0.1800, -0.1975, -0.1975]],\n",
              " \n",
              "          [[-0.1661, -0.1661, -0.1835,  ...,  0.3045,  0.2173,  0.1999],\n",
              "           [-0.1487, -0.1312, -0.1661,  ...,  0.3045,  0.2871,  0.2522],\n",
              "           [-0.0964, -0.0964, -0.0964,  ...,  0.3742,  0.3219,  0.3045],\n",
              "           ...,\n",
              "           [-0.8807, -0.7936, -0.7413,  ...,  0.1651,  0.2522,  0.3045],\n",
              "           [-0.8807, -0.8110, -0.7413,  ...,  0.1651,  0.1476,  0.1651],\n",
              "           [-0.8633, -0.8110, -0.7587,  ...,  0.1825,  0.1476,  0.1128]]],\n",
              " \n",
              " \n",
              "         [[[ 0.6734,  0.6734,  0.6734,  ..., -0.7993, -0.8678, -0.9020],\n",
              "           [ 0.6734,  0.6734,  0.6734,  ..., -0.8164, -0.8678, -0.9020],\n",
              "           [ 0.6734,  0.6734,  0.6734,  ..., -0.8164, -0.8849, -0.9020],\n",
              "           ...,\n",
              "           [-1.7583, -1.7754, -1.7925,  ..., -1.7925, -1.7754, -1.7754],\n",
              "           [-1.8097, -1.8268, -1.8268,  ..., -1.7925, -1.7754, -1.7754],\n",
              "           [-1.8439, -1.8439, -1.8439,  ..., -1.7925, -1.7754, -1.7754]],\n",
              " \n",
              "          [[ 0.8004,  0.8004,  0.8004,  ..., -1.2479, -1.3179, -1.3354],\n",
              "           [ 0.8004,  0.8004,  0.8004,  ..., -1.2654, -1.3179, -1.3354],\n",
              "           [ 0.8004,  0.8004,  0.8004,  ..., -1.2829, -1.3179, -1.3354],\n",
              "           ...,\n",
              "           [-1.5630, -1.5805, -1.6155,  ..., -1.5980, -1.5805, -1.5805],\n",
              "           [-1.6331, -1.6506, -1.6681,  ..., -1.5980, -1.5805, -1.5805],\n",
              "           [-1.6681, -1.6681, -1.6681,  ..., -1.5980, -1.5805, -1.5805]],\n",
              " \n",
              "          [[ 0.7751,  0.7751,  0.7751,  ..., -1.0724, -1.1421, -1.1596],\n",
              "           [ 0.7751,  0.7751,  0.7751,  ..., -1.0898, -1.1421, -1.1596],\n",
              "           [ 0.7751,  0.7751,  0.7751,  ..., -1.1073, -1.1421, -1.1596],\n",
              "           ...,\n",
              "           [-1.4036, -1.4210, -1.4384,  ..., -1.4036, -1.3861, -1.3861],\n",
              "           [-1.4384, -1.4559, -1.4733,  ..., -1.4036, -1.3861, -1.3861],\n",
              "           [-1.4733, -1.4733, -1.4907,  ..., -1.4036, -1.3861, -1.3861]]],\n",
              " \n",
              " \n",
              "         [[[-1.5528, -1.5528, -1.5699,  ..., -1.5357, -1.5185, -1.5185],\n",
              "           [-1.5357, -1.5699, -1.5528,  ..., -1.5357, -1.5185, -1.5185],\n",
              "           [-1.5357, -1.5185, -1.5357,  ..., -1.5528, -1.5357, -1.5357],\n",
              "           ...,\n",
              "           [-0.4054, -0.4054, -0.3712,  ..., -0.6623, -0.6452, -0.6452],\n",
              "           [-0.7822, -0.7137, -0.6109,  ..., -0.6452, -0.6452, -0.6452],\n",
              "           [-1.0048, -0.9020, -0.7308,  ..., -0.6452, -0.6452, -0.6452]],\n",
              " \n",
              "          [[-1.5105, -1.5105, -1.5280,  ..., -0.9678, -0.9503, -0.9503],\n",
              "           [-1.4930, -1.5105, -1.5105,  ..., -0.9503, -0.9328, -0.9328],\n",
              "           [-1.4755, -1.4755, -1.4930,  ..., -0.9328, -0.9153, -0.9153],\n",
              "           ...,\n",
              "           [-0.2325, -0.2325, -0.2150,  ..., -0.5301, -0.5126, -0.5126],\n",
              "           [-0.6001, -0.5301, -0.4426,  ..., -0.5126, -0.5126, -0.5126],\n",
              "           [-0.8277, -0.7577, -0.6176,  ..., -0.5126, -0.5126, -0.5126]],\n",
              " \n",
              "          [[-0.1661, -0.1661, -0.1835,  ..., -1.1421, -1.1247, -1.1247],\n",
              "           [-0.1487, -0.1835, -0.2010,  ..., -1.1421, -1.1247, -1.1247],\n",
              "           [-0.1487, -0.1661, -0.1835,  ..., -1.1770, -1.1421, -1.1421],\n",
              "           ...,\n",
              "           [ 0.9668,  0.9668,  0.9494,  ...,  0.3219,  0.3393,  0.3393],\n",
              "           [ 0.4091,  0.4788,  0.5485,  ...,  0.3393,  0.3393,  0.3393],\n",
              "           [ 0.0605,  0.1651,  0.3219,  ...,  0.3393,  0.3393,  0.3393]]]]),\n",
              " tensor([[1., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0.]])]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test du premier batch dans val_loader...\n",
            "Batch chargé : torch.Size([32, 3, 224, 224]) - torch.Size([32, 8])\n"
          ]
        }
      ],
      "source": [
        "# --- Test 0 : Vérifie si le DataLoader donne quelque chose ---\n",
        "print(\"Test du premier batch dans val_loader...\")\n",
        "\n",
        "try:\n",
        "    sample_batch = next(iter(val_loader))\n",
        "    images, labels = sample_batch\n",
        "    print(f\"Batch chargé : {images.shape} - {labels.shape}\")\n",
        "except Exception as e:\n",
        "    print(\"Erreur pendant le chargement du batch :\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test du premier batch dans train_loader...\n",
            "Batch chargé : torch.Size([32, 3, 224, 224]) - torch.Size([32, 8])\n"
          ]
        }
      ],
      "source": [
        "# --- Test 1 : Vérifie si le DataLoader donne quelque chose ---\n",
        "print(\"Test du premier batch dans train_loader...\")\n",
        "\n",
        "try:\n",
        "    sample_batch = next(iter(train_loader))\n",
        "    images, labels = sample_batch\n",
        "    print(f\"Batch chargé : {images.shape} - {labels.shape}\")\n",
        "except Exception as e:\n",
        "    print(\"Erreur pendant le chargement du batch :\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Test de vitesse du train_loader...\n",
            "🧱 Batch 1 - Temps de chargement + transfert : 0.1370 sec\n",
            "🧱 Batch 2 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 3 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 4 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 5 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 6 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 7 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 8 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 9 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 10 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 11 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 12 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 13 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 14 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 15 - Temps de chargement + transfert : 0.0030 sec\n",
            "🧱 Batch 16 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 17 - Temps de chargement + transfert : 0.0050 sec\n",
            "🧱 Batch 18 - Temps de chargement + transfert : 0.0050 sec\n",
            "🧱 Batch 19 - Temps de chargement + transfert : 0.0040 sec\n",
            "🧱 Batch 20 - Temps de chargement + transfert : 0.0060 sec\n",
            "\n",
            "📊 Moyenne sur 20 batches :\n",
            "⏱ Temps moyen par batch : 0.0104 sec\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# Active le DataLoader uniquement\n",
        "print(\"⏳ Test de vitesse du train_loader...\")\n",
        "\n",
        "n_batches_to_test = 20  # Tu peux ajuster selon la taille de ton dataset\n",
        "total_load_time = 0.0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for i, (inputs, labels) in enumerate(train_loader):\n",
        "    if i >= n_batches_to_test:\n",
        "        break\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Envoie au GPU (si utile pour tester l'impact)\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Attendre que les données soient vraiment transférées\n",
        "    torch.cuda.synchronize() if device.type == \"cuda\" else None\n",
        "\n",
        "    end = time.time()\n",
        "    load_time = end - start\n",
        "    total_load_time += load_time\n",
        "    print(f\"🧱 Batch {i+1} - Temps de chargement + transfert : {load_time:.4f} sec\")\n",
        "\n",
        "print(\"\\n📊 Moyenne sur\", n_batches_to_test, \"batches :\")\n",
        "print(f\"⏱ Temps moyen par batch : {total_load_time / n_batches_to_test:.4f} sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[[ 0.9988,  0.9988,  0.9988,  ...,  1.2557,  1.1872,  1.1700],\n",
            "         [ 0.9817,  0.9817,  0.9817,  ...,  1.1187,  1.1187,  1.1358],\n",
            "         [ 0.9817,  0.9817,  0.9817,  ...,  1.0159,  1.0159,  1.0331],\n",
            "         ...,\n",
            "         [-0.9192, -0.8849, -0.7822,  ...,  0.7077,  0.7077,  0.7077],\n",
            "         [-0.8849, -0.9020, -0.7822,  ...,  0.7248,  0.7248,  0.7248],\n",
            "         [-0.8678, -0.8849, -0.7993,  ...,  0.7419,  0.7419,  0.7419]],\n",
            "\n",
            "        [[ 1.1331,  1.1331,  1.1331,  ...,  1.3256,  1.2906,  1.2906],\n",
            "         [ 1.0805,  1.0805,  1.0805,  ...,  1.2031,  1.2381,  1.2381],\n",
            "         [ 1.0805,  1.0805,  1.0805,  ...,  1.1331,  1.1331,  1.1331],\n",
            "         ...,\n",
            "         [-0.8627, -0.8452, -0.7752,  ...,  0.9055,  0.9055,  0.9055],\n",
            "         [-0.8277, -0.8627, -0.7927,  ...,  0.9405,  0.9405,  0.9405],\n",
            "         [-0.8102, -0.8452, -0.7927,  ...,  0.9580,  0.9580,  0.9580]],\n",
            "\n",
            "        [[ 2.0648,  2.0648,  2.0648,  ...,  2.1171,  2.1346,  2.1520],\n",
            "         [ 2.0300,  2.0300,  2.0300,  ...,  2.1520,  2.1694,  2.1868],\n",
            "         [ 2.0300,  2.0300,  2.0300,  ...,  2.2566,  2.2740,  2.2914],\n",
            "         ...,\n",
            "         [-0.5321, -0.4624, -0.3230,  ...,  1.0017,  1.0017,  1.0017],\n",
            "         [-0.4798, -0.4798, -0.3753,  ...,  1.0191,  1.0191,  1.0191],\n",
            "         [-0.4624, -0.4624, -0.3753,  ...,  1.0539,  1.0539,  1.0539]]]), tensor([0., 0., 0., 0., 0., 0., 1., 0.]))\n",
            "(tensor([[[-1.6898, -1.6727, -1.6384,  ..., -0.1143,  0.2111,  0.3481],\n",
            "         [-1.6727, -1.6555, -1.6213,  ...,  0.0741,  0.3481,  0.5022],\n",
            "         [-1.6384, -1.6213, -1.5699,  ...,  0.3823,  0.6049,  0.7419],\n",
            "         ...,\n",
            "         [-1.1247, -1.1075, -1.0733,  ...,  0.5022,  0.4337,  0.4166],\n",
            "         [-1.1247, -1.1075, -1.0733,  ...,  0.4508,  0.4166,  0.4337],\n",
            "         [-1.1247, -1.1075, -1.0733,  ...,  0.4166,  0.4337,  0.4166]],\n",
            "\n",
            "        [[-1.5630, -1.5455, -1.5280,  ...,  0.0651,  0.4153,  0.5553],\n",
            "         [-1.5280, -1.5455, -1.4930,  ...,  0.2402,  0.5553,  0.7129],\n",
            "         [-1.5105, -1.4930, -1.4405,  ...,  0.5553,  0.8354,  0.9580],\n",
            "         ...,\n",
            "         [-1.2304, -1.2129, -1.1779,  ...,  0.6254,  0.5903,  0.5728],\n",
            "         [-1.2129, -1.2129, -1.1779,  ...,  0.5728,  0.5728,  0.5378],\n",
            "         [-1.2129, -1.2129, -1.1779,  ...,  0.5728,  0.5553,  0.5378]],\n",
            "\n",
            "        [[-1.0550, -1.0376, -1.0027,  ..., -0.0267,  0.3568,  0.4962],\n",
            "         [-1.0550, -1.0376, -1.0027,  ...,  0.1476,  0.4962,  0.6356],\n",
            "         [-1.0724, -1.0550, -1.0201,  ...,  0.4614,  0.7576,  0.9145],\n",
            "         ...,\n",
            "         [-0.9156, -0.9156, -0.8981,  ..., -0.0441, -0.1312, -0.1312],\n",
            "         [-0.9156, -0.9156, -0.9156,  ..., -0.1312, -0.2010, -0.2184],\n",
            "         [-0.9504, -0.9156, -0.9156,  ..., -0.1661, -0.2184, -0.2707]]]), tensor([0., 0., 0., 0., 0., 0., 1., 0.]))\n"
          ]
        }
      ],
      "source": [
        "for i in range (2):\n",
        "    print(train_dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# V/ Chargement du modèle ResNet18 pré-entraîné"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chargement et modification du modèle ResNet18 pré-entraîné...\n",
            "Freeze des couches convolutionnelles...\n",
            "Définition de la dernière couche...\n",
            "Modèle prêt ! ✅\n"
          ]
        }
      ],
      "source": [
        "print(\"Chargement et modification du modèle ResNet18 pré-entraîné...\")\n",
        "\n",
        "# 1. Chargement du modèle ResNet18 pré-entraîné sur ImageNet\n",
        "model_ft = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "print(\"Freeze des couches convolutionnelles...\")\n",
        "\n",
        "# 2. On gèle les couches de feature extraction\n",
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"Définition de la dernière couche...\")\n",
        "\n",
        "# 3. Remplacement de la couche fully-connected finale\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),   # Couche cachée intermédiaire\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, NUM_CLASSES),  # Sortie adaptée au nombre d’émotions\n",
        "    nn.Sigmoid()  # Activation pour classification multi-label\n",
        ")\n",
        "\n",
        "# 4. Envoi du modèle sur le bon device (GPU ou CPU)\n",
        "model_ft = model_ft.to(DEVICE)\n",
        "\n",
        "print(\"Modèle prêt ! ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=8, bias=True)\n",
            "    (4): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [1, 8]                    --\n",
              "├─Conv2d: 1-1                            [1, 64, 112, 112]         (9,408)\n",
              "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         (128)\n",
              "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
              "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
              "├─Sequential: 1-5                        [1, 64, 56, 56]           --\n",
              "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           --\n",
              "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           (36,864)\n",
              "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           (128)\n",
              "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
              "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           (36,864)\n",
              "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           (128)\n",
              "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
              "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           --\n",
              "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           (36,864)\n",
              "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           (128)\n",
              "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           --\n",
              "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           (36,864)\n",
              "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           (128)\n",
              "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           --\n",
              "├─Sequential: 1-6                        [1, 128, 28, 28]          --\n",
              "│    └─BasicBlock: 2-3                   [1, 128, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-13                 [1, 128, 28, 28]          (73,728)\n",
              "│    │    └─BatchNorm2d: 3-14            [1, 128, 28, 28]          (256)\n",
              "│    │    └─ReLU: 3-15                   [1, 128, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-16                 [1, 128, 28, 28]          (147,456)\n",
              "│    │    └─BatchNorm2d: 3-17            [1, 128, 28, 28]          (256)\n",
              "│    │    └─Sequential: 3-18             [1, 128, 28, 28]          (8,448)\n",
              "│    │    └─ReLU: 3-19                   [1, 128, 28, 28]          --\n",
              "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-20                 [1, 128, 28, 28]          (147,456)\n",
              "│    │    └─BatchNorm2d: 3-21            [1, 128, 28, 28]          (256)\n",
              "│    │    └─ReLU: 3-22                   [1, 128, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-23                 [1, 128, 28, 28]          (147,456)\n",
              "│    │    └─BatchNorm2d: 3-24            [1, 128, 28, 28]          (256)\n",
              "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          --\n",
              "├─Sequential: 1-7                        [1, 256, 14, 14]          --\n",
              "│    └─BasicBlock: 2-5                   [1, 256, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-26                 [1, 256, 14, 14]          (294,912)\n",
              "│    │    └─BatchNorm2d: 3-27            [1, 256, 14, 14]          (512)\n",
              "│    │    └─ReLU: 3-28                   [1, 256, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-29                 [1, 256, 14, 14]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-30            [1, 256, 14, 14]          (512)\n",
              "│    │    └─Sequential: 3-31             [1, 256, 14, 14]          (33,280)\n",
              "│    │    └─ReLU: 3-32                   [1, 256, 14, 14]          --\n",
              "│    └─BasicBlock: 2-6                   [1, 256, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-33                 [1, 256, 14, 14]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-34            [1, 256, 14, 14]          (512)\n",
              "│    │    └─ReLU: 3-35                   [1, 256, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-36                 [1, 256, 14, 14]          (589,824)\n",
              "│    │    └─BatchNorm2d: 3-37            [1, 256, 14, 14]          (512)\n",
              "│    │    └─ReLU: 3-38                   [1, 256, 14, 14]          --\n",
              "├─Sequential: 1-8                        [1, 512, 7, 7]            --\n",
              "│    └─BasicBlock: 2-7                   [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-39                 [1, 512, 7, 7]            (1,179,648)\n",
              "│    │    └─BatchNorm2d: 3-40            [1, 512, 7, 7]            (1,024)\n",
              "│    │    └─ReLU: 3-41                   [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-42                 [1, 512, 7, 7]            (2,359,296)\n",
              "│    │    └─BatchNorm2d: 3-43            [1, 512, 7, 7]            (1,024)\n",
              "│    │    └─Sequential: 3-44             [1, 512, 7, 7]            (132,096)\n",
              "│    │    └─ReLU: 3-45                   [1, 512, 7, 7]            --\n",
              "│    └─BasicBlock: 2-8                   [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-46                 [1, 512, 7, 7]            (2,359,296)\n",
              "│    │    └─BatchNorm2d: 3-47            [1, 512, 7, 7]            (1,024)\n",
              "│    │    └─ReLU: 3-48                   [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-49                 [1, 512, 7, 7]            (2,359,296)\n",
              "│    │    └─BatchNorm2d: 3-50            [1, 512, 7, 7]            (1,024)\n",
              "│    │    └─ReLU: 3-51                   [1, 512, 7, 7]            --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
              "├─Sequential: 1-10                       [1, 8]                    --\n",
              "│    └─Linear: 2-9                       [1, 512]                  262,656\n",
              "│    └─ReLU: 2-10                        [1, 512]                  --\n",
              "│    └─Dropout: 2-11                     [1, 512]                  --\n",
              "│    └─Linear: 2-12                      [1, 8]                    4,104\n",
              "│    └─Sigmoid: 2-13                     [1, 8]                    --\n",
              "==========================================================================================\n",
              "Total params: 11,443,272\n",
              "Trainable params: 266,760\n",
              "Non-trainable params: 11,176,512\n",
              "Total mult-adds (Units.GIGABYTES): 1.81\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.74\n",
              "Params size (MB): 45.77\n",
              "Estimated Total Size (MB): 86.12\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Print model summary\n",
        "#summary(model_ft, input_size=(8, 3, 224, 224))  # (batch_size, input_features)\n",
        "summary(model_ft, input_size=(1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VI/ Fonction de perte et Optimiseur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PAV_C7MYUH2A"
      },
      "outputs": [],
      "source": [
        "# --- 5. Fonction de perte et Optimiseur ---\n",
        "# Pour la classification multi-label, Binary Cross-Entropy with Logits Loss est la norme.\n",
        "# Elle combine une couche Sigmoid et la Binary Cross-Entropy.\n",
        "# Perte pour la classification multi-label des émotions\n",
        "\n",
        "# criterion_emotions = nn.BCEWithLogitsLoss()\n",
        "# criterion_emotions = nn.CrossEntropyLoss()\n",
        "criterion_emotions = nn.BCELoss()\n",
        "\n",
        "# Seulement les paramètres qui nécessitent des gradients seront optimisés\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Ordonnanceur de taux d'apprentissage (réduit le LR après un certain nombre d'époques)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VII/ Fonction d'entraînement et d'évaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 6. Fonction d'entraînement et d'évaluation ---\n",
        "import time\n",
        "\n",
        "def train_model(model, criterion_emotions, optimizer, train_loader, val_loader, device, scheduler=None, epochs=NUM_EPOCHS):\n",
        "    \n",
        "    since = time.time()\n",
        "    \n",
        "    history = {'train_loss': [], 'val_loss': [],'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print('-' * 30)\n",
        "\n",
        "        ### -------- TRAIN --------\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion_emotions(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Accuracy multi-label (threshold 0.5)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            running_corrects += (preds == labels).float().sum().item()\n",
        "            total_samples += labels.numel()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects / total_samples\n",
        "\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc)\n",
        "\n",
        "        ### -------- VAL --------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion_emotions(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                val_corrects += (preds == labels).float().sum().item()\n",
        "                val_total += labels.numel()\n",
        "\n",
        "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
        "        val_epoch_acc = val_corrects / val_total\n",
        "\n",
        "        history['val_loss'].append(val_epoch_loss)\n",
        "        history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Val   Loss: {val_epoch_loss:.4f} | Acc: {val_epoch_acc:.4f}\")\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"\\n🕒 Entraînement terminé en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "------------------------------\n",
            "Train Loss: 0.1702 | Acc: 0.1545\n",
            "Val   Loss: 0.1585 | Acc: 0.1544\n",
            "\n",
            "Epoch 2/10\n",
            "------------------------------\n",
            "Train Loss: 0.1634 | Acc: 0.1545\n",
            "Val   Loss: 0.1598 | Acc: 0.1544\n",
            "\n",
            "Epoch 3/10\n",
            "------------------------------\n",
            "Train Loss: 0.1630 | Acc: 0.1545\n",
            "Val   Loss: 0.1645 | Acc: 0.1544\n",
            "\n",
            "Epoch 4/10\n",
            "------------------------------\n",
            "Train Loss: 0.1616 | Acc: 0.1545\n",
            "Val   Loss: 0.1564 | Acc: 0.1544\n",
            "\n",
            "Epoch 5/10\n",
            "------------------------------\n",
            "Train Loss: 0.1613 | Acc: 0.1545\n",
            "Val   Loss: 0.1571 | Acc: 0.1544\n",
            "\n",
            "Epoch 6/10\n",
            "------------------------------\n",
            "Train Loss: 0.1610 | Acc: 0.1545\n",
            "Val   Loss: 0.1570 | Acc: 0.1544\n",
            "\n",
            "Epoch 7/10\n",
            "------------------------------\n",
            "Train Loss: 0.1607 | Acc: 0.1545\n",
            "Val   Loss: 0.1558 | Acc: 0.1544\n",
            "\n",
            "Epoch 8/10\n",
            "------------------------------\n",
            "Train Loss: 0.1564 | Acc: 0.1545\n",
            "Val   Loss: 0.1568 | Acc: 0.1544\n",
            "\n",
            "Epoch 9/10\n",
            "------------------------------\n",
            "Train Loss: 0.1572 | Acc: 0.1545\n",
            "Val   Loss: 0.1552 | Acc: 0.1544\n",
            "\n",
            "Epoch 10/10\n",
            "------------------------------\n",
            "Train Loss: 0.1575 | Acc: 0.1545\n",
            "Val   Loss: 0.1552 | Acc: 0.1544\n",
            "\n",
            "🕒 Entraînement terminé en 35m 13s\n"
          ]
        }
      ],
      "source": [
        "history = train_model(model=model_ft,\n",
        "                        criterion_emotions=criterion_emotions,\n",
        "                        optimizer=optimizer_ft,\n",
        "                        train_loader=train_loader,\n",
        "                        val_loader=val_loader,\n",
        "                        device=DEVICE,\n",
        "                        scheduler=exp_lr_scheduler,\n",
        "                        epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VIII/ Lancement de l'entraînement "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o26pD-BuUfA6"
      },
      "outputs": [],
      "source": [
        "# # --- 7. Lancement de l'entraînement ---\n",
        "# print(\"\\nDébut de l'entraînement...\")\n",
        "# model_ft = train_model(model_ft, criterion_emotions, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modèle exporté au format ONNX : emotic_model.onnx\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sauvegarde\n",
        "onnx_export_path = \"emotic_model.onnx\"\n",
        "\n",
        "# Dummy input — doit correspondre à la taille attendue par ton modèle\n",
        "dummy_input = torch.randn(1, 3, 224, 224, device=DEVICE)\n",
        "\n",
        "# Export ONNX\n",
        "torch.onnx.export(\n",
        "    model_ft,                  # Le modèle entraîné\n",
        "    dummy_input,               # Un exemple d'input\n",
        "    onnx_export_path,          # Chemin de sortie\n",
        "    input_names=['input'],     # Nom de l'input\n",
        "    output_names=['output'],   # Nom de la sortie\n",
        "    dynamic_axes={\n",
        "        'input': {0: 'batch_size'},\n",
        "        'output': {0: 'batch_size'}\n",
        "    },\n",
        "    opset_version=11,          # Version de l'opset ONNX (11 est sûr pour la compatibilité)\n",
        "    do_constant_folding=True   # Optimisation pour les constantes\n",
        ")\n",
        "\n",
        "print(f\"✅ Modèle exporté au format ONNX : {onnx_export_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zOnRjwFUhgo"
      },
      "outputs": [],
      "source": [
        "# # --- 8. Sauvegarde du modèle entraîné ---\n",
        "# # Créez un dossier pour les modèles si n'existe pas\n",
        "# os.makedirs('saved_models', exist_ok=True)\n",
        "# model_save_path = os.path.join('saved_models', 'resnet18_emotion_dav_multi_person.pth')\n",
        "# torch.save(model_ft.state_dict(), model_save_path)\n",
        "# print(f\"Modèle sauvegardé à : {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AR5Dl7-GCrI"
      },
      "outputs": [],
      "source": [
        "# --- 9. (Optionnel) Évaluation finale sur l'ensemble de validation ---\n",
        "# Charger le modèle pour l'évaluation\n",
        "# model_ft.eval() # Mettre en mode évaluation\n",
        "# ... Vous pouvez réutiliser le code d'évaluation de la fonction train_model ici si vous voulez une évaluation finale séparée.\n",
        "\n",
        "print(\"\\n--- Entraînement terminé ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import onnxruntime as ort\n",
        "# import numpy as np\n",
        "# from torchvision import transforms\n",
        "# from PIL import Image\n",
        "\n",
        "# # Charger le modèle ONNX\n",
        "# session = ort.InferenceSession(\"emotic_model.onnx\")\n",
        "\n",
        "# # Charger et prétraiter une image\n",
        "# img_path = \"chemin/vers/image.jpg\"\n",
        "# image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], \n",
        "#                          [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# input_tensor = transform(image).unsqueeze(0).numpy()  # (1, 3, 224, 224)\n",
        "\n",
        "# # Faire une prédiction\n",
        "# outputs = session.run(['output'], {'input': input_tensor})\n",
        "# preds = outputs[0]\n",
        "\n",
        "# # Résultat\n",
        "# print(\"Prédiction brute :\", preds)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_project_py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
