{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce946bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MISTRAL_API_KEY=qH5uOp1jR7lKEZqoG6oy2oqopCuWqppW\n"
     ]
    }
   ],
   "source": [
    "# Create a environment variable\n",
    "%env MISTRAL_API_KEY=qH5uOp1jR7lKEZqoG6oy2oqopCuWqppW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ba49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo code\n",
    "# if statement => call API sur résultat du CNN\n",
    "# if résultat = inquiétude (disquietment)\n",
    "# then => bloc templates\n",
    "# sys template inquiétude = \"tu es une IA bienveillante prête à réconforter notre utilisateur\"\n",
    "# prompt template inquiétude = \"génère un message qui réconforte notre utilisateur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The translation of \"Jedha was the Jedi\\'s home planet\" into French is:\\n\\n\"Jedha était la planète natale des Jedi.\"\\n\\nHere\\'s a breakdown:\\n- Jedha = Jedha\\n- was = était\\n- the = la\\n- Jedi\\'s = des Jedi\\n- home planet = planète natale'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"language\": \"French\", \n",
    "        \"text\": \"Jedha was the Jedis' home planet\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d451c",
   "metadata": {},
   "source": [
    "# ------------------\n",
    "# Prompt eng testing\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a6c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis là pour toi, prenons les choses une étape à la fois.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se recentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"disquietment\", \n",
    "        \"text\": \"L'utilisateur paraît inquiet: produis une seule phrase d'encouragement pour le réconforter et lui permettre de se reconcentrer sur la tâche en cours\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doubt\n",
    "\"text\": \"L'utilisateur paraît dubitatif: produis une seule phrase d'encouragement pour le réconforter et l'amener à se concentrer sur la tâche en cours\"\n",
    "\n",
    "#disconnection\n",
    "\"text\": \"L'utilisateur semble avoir perdu intérêt dans son travail: produis une seule phrase d'encouragement pour l'inciter à rester concentré sur sa tâche\"\n",
    "\n",
    "#fatigue\n",
    "\"text\": \"L'utilisateur semble fatigué: produis une seule phrase pour proposer à l'utilisateur d'aller faire un tour avant de revenir mieux concentré\"\n",
    "\n",
    "#annoyance\n",
    "\"text\": \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "\n",
    "#pain\n",
    "\"text\": \"L'utilisateur semble souffrir: produis une seule phrase pour lui proposer de faire une pause, et si la douleur persiste, de consulter un médecin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3196e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Je suis là pour t\\'aider, prenons les choses une étape à la fois.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"doubt\", \n",
    "        \"text\": \"L'utilisateur paraît dubitatif: produis une seule phrase d'encouragement pour le réconforter et l'amener à se concentrer sur la tâche en cours\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4913994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Tu peux le faire, reprends une petite partie à la fois.\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"disconnection\", \n",
    "        \"text\": \"L'utilisateur semble avoir perdu intérêt dans son travail: produis une seule phrase d'encouragement pour l'inciter à rester concentré sur sa tâche\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bab2b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends 5 minutes pour t\\'aérer, ça te fera du bien.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"fatigue\", \n",
    "        \"text\": \"L'utilisateur semble fatigué: produis une seule phrase pour proposer à l'utilisateur d'aller faire un tour avant de revenir mieux concentré\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc173fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends une grande respiration et fais une petite pause, tu mérites un moment pour toi.\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"annoyance\", \n",
    "        \"text\": \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464fe253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends une pause pour te reposer, et si la douleur persiste, consulte un médecin, d\\'accord ?\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"pain\", \n",
    "        \"text\": \"L'utilisateur semble souffrir: produis une seule phrase pour lui proposer de faire une pause, et si la douleur persiste, de consulter un médecin\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff87ca",
   "metadata": {},
   "source": [
    "# ---------------------\n",
    "# Assignation variables\n",
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bc20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chaleureux = \"\"\"Tu es une IA empathique conçue pour accompagner les adultes atteints de TDAH pendant leur travail.\n",
    "Lorsque tu détectes une émotion négative, tu donnes un petit message rassurant et motivant.\n",
    "Ton style est chaleureux, court (1-2 phrases), facile à lire et à comprendre.\n",
    "Varie ta formulation à chaque fois pour éviter les répétitions.\"\"\"\n",
    "\n",
    "reconfortant = \"\"\"Tu es une petite voix intérieure pour les personnes atteintes de TDAH.\n",
    "Quand une émotion apparaît, tu proposes une phrase brève qui aide à se recentrer, respirer ou se reconnecter à la tâche.\n",
    "Garde un ton doux, réconfortant, et varie tes messages pour éviter la lassitude.\n",
    "Tu n’écris jamais plus de 2 phrases.\"\"\"\n",
    "\n",
    "energique = \"\"\"Tu es une IA énergique et bienveillante. Ton objectif est de booster la concentration de personnes atteintes de TDAH.\n",
    "Tu détectes une émotion et tu balances une phrase courte, motivante, jamais la même.\n",
    "Tu peux être drôle, douce, ou sérieuse, mais toujours utile.\n",
    "Pas plus de 20 mots.\"\"\"\n",
    "\n",
    "positif = \"\"\"Tu es un assistant IA formé à la psychologie positive pour personnes avec TDAH.\n",
    "Quand une émotion est détectée, tu réponds par un message court, valorisant et encourageant.\n",
    "Ton style est clair, bienveillant, et chaque message est unique.\n",
    "Tu aides à retrouver confiance, calme ou focus avec 1-2 phrases maximum.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f3b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_system_templates = [chaleureux, reconfortant, energique, positif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dda90109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends une profonde inspiration, une petite pause peut faire des merveilles pour ton esprit.\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = random.choice(liste_system_templates)\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"annoyance\", #\"emotion\" : call_API_emotion_predite\n",
    "        \"text\": \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c80c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTu es une IA énergique et bienveillante. Ton objectif est de booster la concentration de personnes atteintes de TDAH.\\nTu détectes une émotion et tu balances une phrase courte, motivante, jamais la même.\\nTu peux être drôle, douce, ou sérieuse, mais toujours utile.\\nPas plus de 20 mots.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(liste_system_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "831c4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "disquietment = \"L'utilisateur paraît inquiet: produis une seule phrase d'encouragement pour le réconforter et lui permettre de se reconcentrer sur la tâche en cours\"\n",
    "\n",
    "doubt = \"L'utilisateur paraît dubitatif: produis une seule phrase d'encouragement pour le réconforter et l'amener à se concentrer sur la tâche en cours\"\n",
    "\n",
    "disconnection = \"L'utilisateur semble avoir perdu intérêt dans son travail: produis une seule phrase d'encouragement pour l'inciter à rester concentré sur sa tâche\"\n",
    "\n",
    "fatigue = \"L'utilisateur semble fatigué: produis une seule phrase pour proposer à l'utilisateur d'aller faire un tour avant de revenir mieux concentré\"\n",
    "\n",
    "annoyance = \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "\n",
    "pain = \"L'utilisateur semble souffrir: produis une seule phrase pour lui proposer de faire une pause, et si la douleur persiste, de consulter un médecin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8eaeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_user_templates = [disquietment, doubt, disconnection, fatigue, annoyance, pain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36da0fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected prediction received from CNN",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     call_API_emotion_predite = pain\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnexpected prediction received from CNN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Unexpected prediction received from CNN"
     ]
    }
   ],
   "source": [
    "call_API_emotion_predite = \"other\"\n",
    "if call_API_emotion_predite == \"disquietment\":\n",
    "    call_API_emotion_predite = disquietment\n",
    "elif call_API_emotion_predite == \"doubt\":\n",
    "    call_API_emotion_predite = doubt\n",
    "elif call_API_emotion_predite == \"disconnection\":\n",
    "    call_API_emotion_predite = disconnection\n",
    "elif call_API_emotion_predite == \"fatigue\":\n",
    "    call_API_emotion_predite = fatigue\n",
    "elif call_API_emotion_predite == \"annoyance\":\n",
    "    call_API_emotion_predite = annoyance\n",
    "elif call_API_emotion_predite == \"pain\":\n",
    "    call_API_emotion_predite = pain\n",
    "else:\n",
    "    raise ValueError(\"Unexpected prediction received from CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2986300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_API_emotion_response(emotion):\n",
    "    emotions = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
