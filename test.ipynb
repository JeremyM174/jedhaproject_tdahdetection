{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce946bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MISTRAL_API_KEY=qH5uOp1jR7lKEZqoG6oy2oqopCuWqppW\n"
     ]
    }
   ],
   "source": [
    "# Create a environment variable\n",
    "%env MISTRAL_API_KEY=qH5uOp1jR7lKEZqoG6oy2oqopCuWqppW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3da4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ba49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo code\n",
    "# if statement => call API sur résultat du CNN\n",
    "# if résultat = inquiétude (disquietment)\n",
    "# then => bloc templates\n",
    "# sys template inquiétude = \"tu es une IA bienveillante prête à réconforter notre utilisateur\"\n",
    "# prompt template inquiétude = \"génère un message qui réconforte notre utilisateur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The translation of \"Jedha was the Jedi\\'s home planet\" into French is:\\n\\n\"Jedha était la planète natale des Jedi.\"\\n\\nHere\\'s a breakdown:\\n- Jedha = Jedha\\n- was = était\\n- the = la\\n- Jedi\\'s = des Jedi\\n- home planet = planète natale'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"language\": \"French\", \n",
    "        \"text\": \"Jedha was the Jedis' home planet\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8a6c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis là pour toi, prenons les choses une étape à la fois.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"disquietment\", \n",
    "        \"text\": \"L'utilisateur paraît inquiet: produis une seule phrase d'encouragement pour le réconforter et lui permettre de se reconcentrer sur la tâche en cours\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doubt\n",
    "\"text\": \"L'utilisateur paraît dubitatif: produis une seule phrase d'encouragement pour le réconforter et l'amener à se concentrer sur la tâche en cours\"\n",
    "\n",
    "#disconnection\n",
    "\"text\": \"L'utilisateur semble avoir perdu intérêt dans son travail: produis une seule phrase d'encouragement pour l'inciter à rester concentré sur sa tâche\"\n",
    "\n",
    "#fatigue\n",
    "\"text\": \"L'utilisateur semble fatigué: produis une seule phrase pour proposer à l'utilisateur d'aller faire un tour avant de revenir mieux concentré\"\n",
    "\n",
    "#annoyance\n",
    "\"text\": \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "\n",
    "#pain\n",
    "\"text\": \"L'utilisateur semble souffrir: produis une seule phrase pour lui proposer de faire une pause, et si la douleur persiste, de consulter un médecin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3196e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Je suis là pour t\\'aider, prenons les choses une étape à la fois.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"doubt\", \n",
    "        \"text\": \"L'utilisateur paraît dubitatif: produis une seule phrase d'encouragement pour le réconforter et l'amener à se concentrer sur la tâche en cours\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4913994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Tu peux le faire, reprends une petite partie à la fois.\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"disconnection\", \n",
    "        \"text\": \"L'utilisateur semble avoir perdu intérêt dans son travail: produis une seule phrase d'encouragement pour l'inciter à rester concentré sur sa tâche\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bab2b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends 5 minutes pour t\\'aérer, ça te fera du bien.\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"fatigue\", \n",
    "        \"text\": \"L'utilisateur semble fatigué: produis une seule phrase pour proposer à l'utilisateur d'aller faire un tour avant de revenir mieux concentré\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc173fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends une grande respiration et fais une petite pause, tu mérites un moment pour toi.\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"annoyance\", \n",
    "        \"text\": \"L'utilisateur semble agacé: produis une seule phrase pour proposer à l'utilisateur de souffler, faire une pause pour revenir dans un meilleur état d'esprit\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464fe253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Prends une pause pour te reposer, et si la douleur persiste, consulte un médecin, d\\'accord ?\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"Tu es une IA bienveillante destinée à des personnes atteintes de TDAH. Sois concis en évitant les phrases longues, et sois gentil et doux: à partir de l'{émotion} détectée, propose une phrase courte et empathique pour aider notre utilisateur à se reconcentrer:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "pipe_sequence = (\n",
    "    prompt_template\n",
    "    .pipe(model)\n",
    "    .pipe(parser)\n",
    ")\n",
    "\n",
    "pipe_sequence.invoke({\n",
    "        \"émotion\": \"pain\", \n",
    "        \"text\": \"L'utilisateur semble souffrir: produis une seule phrase pour lui proposer de faire une pause, et si la douleur persiste, de consulter un médecin\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff87ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
