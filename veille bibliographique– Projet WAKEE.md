# ğŸ“š RÃ©fÃ©rences & CrÃ©dits â€“ Projet WAKEE

Ce document regroupe toutes les **rÃ©fÃ©rences scientifiques, techniques et crÃ©dits** utilisÃ©s pour le dÃ©veloppement de **WAKEE**, une application locale de dÃ©tection dâ€™Ã©motions et dâ€™aide Ã  la concentration.

---

## ğŸ“Š Dataset principal : DAiSEE

Le projet WAKEE s'appuie principalement sur le dataset **DAiSEE** (*Dataset for Affective States in E-learning Environments*), conÃ§u pour analyser l'engagement des utilisateurs dans un contexte dâ€™apprentissage en ligne.

### ğŸ§¾ DÃ©tails du dataset :
- **CrÃ©ateurs** : Gupta, Dâ€™Cunha, Awasthi, Balasubramanian (Indian Institute of Technology Hyderabad)
- **Participants** : 112 individus filmÃ©s en conditions rÃ©elles
- **Volume** : 9â€¯068 vidÃ©os (~25 heures de donnÃ©es)
- **Ã‰tiquettes Ã©motionnelles** : 
  - 4 Ã©motions : Engagement, Ennui (Boredom), Confusion, Frustration
  - 4 niveaux dâ€™intensitÃ© : Very Low, Low, High, Very High
  - Validation par des psychologues et annotations crowdsourcÃ©es

### ğŸ“ Lien vers le dataset :
- Arxiv : https://arxiv.org/abs/1609.01885
- Kaggle : https://www.kaggle.com/datasets/olgaparfenova/daisee

### ğŸ“– RÃ©fÃ©rence complÃ¨te (APA) :
Gupta, A., Dâ€™Cunha, A., Awasthi, K., & Balasubramanian, V. (2016). *DAiSEE: Towards User Engagement Recognition in the Wild*. arXiv preprint arXiv:1609.01885.

---

## ğŸ§  RÃ©fÃ©rences scientifiques complÃ©mentaires

WAKEE sâ€™appuie Ã©galement sur des travaux acadÃ©miques de rÃ©fÃ©rence dans la dÃ©tection des Ã©motions et lâ€™engagement :

1. **Zeng, Z., Pantic, M., Roisman, G.I., & Huang, T.S. (2009).**
   *A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions.* IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(1), 39â€“58.

2. **Bosch, N., Dâ€™Mello, S., & Ocumpaugh, J. (2015).**
   *Detecting student emotions in computer-enabled classrooms.* International Journal of Artificial Intelligence in Education, 25(2), 158â€“190.

---

## âš™ï¸ Technologies & bibliothÃ¨ques utilisÃ©es

WAKEE a Ã©tÃ© dÃ©veloppÃ© en **Python 3.11.13** avec un ensemble de bibliothÃ¨ques spÃ©cialisÃ©es :

- **OpenCV** â€“ pour la capture vidÃ©o et le traitement dâ€™image
- **CNN (Convolutional Neural Network)** â€“ pour analyser les images et dÃ©tecter les Ã©motions
- **LLM (Large Language Model)** â€“ pour gÃ©nÃ©rer des messages empathiques
- **numpy==1.26.4** â€“ calculs numÃ©riques et manipulation des donnÃ©es
- **opencv-python==4.7.0.72** â€“ interface Python pour OpenCV
- **dotenv** â€“ gestion des variables dâ€™environnement
- **pillow** â€“ traitement dâ€™images
- **onnxruntime** â€“ exÃ©cution des modÃ¨les CNN optimisÃ©s
- **torchvision** â€“ outils pour la vision par ordinateur et les CNN
- **langchain_core** â€“ structure pour la gestion du LLM
- **langchain_mistralai** â€“ intÃ©gration avec le modÃ¨le Mistral

---

## ğŸ™ CrÃ©dits & Remerciements

Un grand merci :  
- Aux chercheurs de lâ€™**Indian Institute of Technology Hyderabad** pour la crÃ©ation du dataset **DAiSEE**.  
- Ã€ **Olga Parfenova** pour la mise Ã  disposition des donnÃ©es sur Kaggle.  
- Aux contributeurs des bibliothÃ¨ques **OpenCV**, **PyTorch**, **LangChain** et autres outils open source utilisÃ©s.  
- Aux encadrants et formateurs de **Jedha Bootcamp** pour leur accompagnement et leurs conseils.

---

ğŸ“Œ Ce document constitue la **rÃ©fÃ©rence bibliographique et technique officielle** du projet WAKEE.
